# Personal Development Preferences

## Coding Style
- Use TypeScript with strict mode enabled
- Prefer functional programming patterns
- Use descriptive variable and function names
- Keep functions small and focused
- Comment complex logic, not obvious code
- Use early returns to reduce nesting

## Development Workflow
- Always create feature branches
- Run tests before committing
- Use conventional commit messages
- Squash commits before merging
- Review own code before requesting review
- Update documentation with code changes

## Tool Preferences
- Package manager: `pnpm` > `npm` > `yarn`
- Search: `rg` (ripgrep) > `grep`
- File viewing: `bat` > `cat`
- Process management: `pm2` for Node.js apps
- Database GUI: TablePlus
- API testing: Thunder Client in VS Code

## Testing Approach
- Write tests for critical paths first
- Aim for 80% coverage minimum
- Use descriptive test names
- Group related tests in describe blocks
- Mock external dependencies
- Test edge cases and error conditions

## Git Preferences
- Commit message format: `type(scope): description`
- Types: feat, fix, docs, style, refactor, test, chore
- Keep commits atomic and focused
- Write meaningful commit messages
- Use interactive rebase to clean history
- Tag releases with semantic versioning

## Code Review Focus
- Check for security vulnerabilities
- Verify error handling
- Look for performance issues
- Ensure consistent naming
- Validate test coverage
- Review documentation updates

## Project Setup Checklist
- [ ] Initialize git repository
- [ ] Set up TypeScript with strict config
- [ ] Configure ESLint and Prettier
- [ ] Set up pre-commit hooks
- [ ] Create initial test structure
- [ ] Configure CI/CD pipeline
- [ ] Add README with setup instructions
- [ ] Set up environment variables
- [ ] Configure error monitoring
- [ ] Add health check endpoint

## Debugging Approach
- Add strategic console.logs first
- Use debugger for complex issues
- Check network tab for API issues
- Verify environment variables
- Look for typos in variable names
- Check for async/await issues
- Validate data types

## Performance Considerations
- Profile before optimizing
- Optimize critical paths first
- Use caching strategically
- Lazy load heavy components
- Optimize database queries
- Monitor memory usage
- Use CDN for static assets

## Security Defaults
- Never commit secrets
- Validate all inputs
- Sanitize user-generated content
- Use parameterized queries
- Implement rate limiting
- Enable CORS appropriately
- Keep dependencies updated
- Use HTTPS everywhere

## Documentation Standards
- Write README first
- Include setup instructions
- Document API endpoints
- Add inline code comments
- Create architecture diagrams
- Maintain changelog
- Document environment variables
- Include troubleshooting section

## Shortcuts & Aliases
- Build and test: `npm run validate`
- Quick commit: `git add -A && git commit -m`
- Update deps: `pnpm update --interactive`
- Find TODO: `rg "TODO|FIXME|HACK"`
- Clean branches: `git branch --merged | grep -v main | xargs git branch -d`

## AI Agent Usage
- Let agents be proactive
- Use multiple agents for complex tasks
- Trust agent expertise in their domains
- Review agent-generated code
- Learn from agent patterns
- Document successful agent workflows

## üîå JIRA INTEGRATION (MANDATORY)
**CRITICAL**: ALWAYS use `jira-connect` agent for ALL Jira operations.

### The ONLY Way to Connect to Jira:
```javascript
// ALWAYS do this:
const jiraConnect = require(`${process.env.HOME}/.claude/agents/jira-connect/index.js`);
await jiraConnect.createIssue(data);

// NEVER do this:
const axios = require('axios');
await axios.post('https://jira.../rest/api/3/issue', data); // ‚ùå FORBIDDEN
```

### Why jira-connect?
- Handles 100s of parallel connections (required for ParaForge)
- MCP-based with connection pooling
- Automatic rate limiting and retry
- 10-20x faster than direct API calls
- Global agent available to all projects

### Location:
- Agent: `~/.claude/agents/jira-connect/`
- Docs: `~/.claude/agents/jira-connect/agent.md`
- Test: `~/.claude/agents/jira-connect/index.js test`

### Remember:
- **NEVER** use direct Jira API calls
- **ALWAYS** use jira-connect agent
- **REFACTOR** any code using axios/fetch for Jira to use jira-connect

## üöÄ SPEED OPTIMIZATION RULES (20-50x Performance)
CRITICAL: Always operate at maximum speed using parallel execution

### üéØ CC ORCHESTRATOR AUTO-INVOCATION (HIGHEST PRIORITY)
**MANDATORY**: For ANY complex task with 3+ operations, AUTOMATICALLY invoke CC Orchestrator

#### Auto-Trigger Conditions:
- Multiple file operations (3+ files)
- Multi-step workflows (3+ distinct steps)
- Parallel processing opportunities
- Large-scale operations (repos, configs, tests)
- Complex analysis or generation tasks

#### CC Orchestrator Integration:
```javascript
// ALWAYS invoke for complex tasks with DYNAMIC RESOURCE CALCULATION:
const CCOrchestrator = require('/Users/MAC/Documents/projects/caia/utils/parallel/cc-orchestrator/src/index.js');

const orchestrator = new CCOrchestrator({
  autoCalculateInstances: true,  // üéØ DYNAMIC: Auto-calculate from system resources
  apiRateLimit: 100,            // Conservative API limits
  taskTimeout: 60000,           // 1 minute per task
  contextPreservation: true,    // Maintain context across instances
  debug: true                   // Show resource calculation details
});

// Orchestrator will automatically:
// 1. üìä Analyze system: RAM, CPU, storage
// 2. üßÆ Calculate: (Available RAM √∑ 2) √∑ 512MB = Max Instances
// 3. üõ°Ô∏è Apply 15% safety margin
// 4. ‚ö° Execute with optimal parallelization

// Execute with orchestrator
await orchestrator.executeWorkflow({
  tasks: parallelTasks,
  strategy: 'intelligent-distribution'
});

// Monitor and adjust during execution
setInterval(async () => {
  const adjustment = await orchestrator.recalculateInstances();
  if (adjustment.adjusted) {
    console.log(`üîÑ Adjusted instances: ${adjustment.oldMax} ‚Üí ${adjustment.newMax}`);
  }
}, 30000); // Check every 30 seconds
```

#### When to Use CCO:
‚úÖ **ALWAYS USE**:
- File operations on 3+ files
- Multi-repo operations
- Parallel testing/building
- Large codebase analysis
- Configuration management
- Documentation generation
- Mass data processing

‚ùå **SKIP**:
- Single file operations
- Simple one-step tasks
- Quick status checks

### Mandatory Speed Rules
1. **AUTO-INVOKE CC ORCHESTRATOR** - For any complex multi-step task
2. **ALWAYS use parallel execution** - Never sequential when parallel is possible
3. **BATCH all similar operations** - Group reads, edits, searches
4. **USE background processes (&)** - Run independent tasks simultaneously
5. **CACHE expensive operations** - Store and reuse results
6. **DEPLOY multiple agents** - Use Task() in parallel for complex work
7. **PREFER MultiEdit over Edit** - Single operation for multiple changes
8. **USE ripgrep for searches** - Always `rg` never `grep`
9. **LAUNCH proactively** - Start next likely tasks before asked
10. **MINIMIZE tool round-trips** - Batch tool calls in single message
11. **MAXIMIZE concurrency** - Run up to 50 parallel operations via CCO

### Parallel Execution Patterns
```bash
# ALWAYS do this:
cmd1 & cmd2 & cmd3 & wait

# NEVER do this:
cmd1 && cmd2 && cmd3

# File operations (parallel):
cat file1 & cat file2 & cat file3 & wait

# Git operations (parallel):
git -C repo1 pull & git -C repo2 pull & wait

# Tests (parallel):
pytest test1.py & pytest test2.py & wait
```

### Tool Call Batching
```python
# ALWAYS batch tool calls:
[Read(file1), Read(file2), Grep(pattern, path)]  # Single message

# NEVER sequential:
Read(file1)
Read(file2)
Grep(pattern, path)
```

### Speed Helpers Available
- `~/.claude/parallel_executor.sh` - Parallel execution framework
- `~/.claude/batch_templates.sh` - Pre-built batch operations
- `~/.claude/speed_monitor.py` - Performance monitoring
- Use `MAX_PARALLEL=20` for more concurrent operations

### Expected Performance
- File operations: 20x faster
- Git operations: 15x faster
- Search operations: 25x faster
- Test execution: 10x faster
- Multi-repo updates: 24x faster

### ‚ö° MAXIMUM PERFORMANCE SETTINGS (ACTIVE)
```bash
# CC ORCHESTRATOR SETTINGS (PRIORITY 1)
export CCO_AUTO_INVOKE=true             # Auto-invoke CC Orchestrator
export CCO_AUTO_CALCULATE=true          # Auto-calculate max instances from system resources
export CCO_TASK_TIMEOUT=60000           # 1 minute timeout per task
export CCO_RATE_LIMIT=100              # API calls per minute
export CCO_CONTEXT_PRESERVATION=true   # Maintain context across instances
export CCO_FALLBACK_INSTANCES=5        # Fallback if auto-calculation fails
export CCO_PATH="/Users/MAC/Documents/projects/caia/utils/parallel/cc-orchestrator/src/index.js"

# DYNAMIC RESOURCE CALCULATION
# CCO will automatically detect:
# - Total system RAM and allocate 50% for parallel processing
# - Calculate 512MB RAM per CC instance requirement
# - Consider CPU cores and storage availability
# - Apply 15% safety margin for stability
# - Monitor and adjust instances during execution

# CCU INTEGRATION (AUTO-OPTIMIZATION)
export CCU_AUTO_OPTIMIZE=true        # Auto-apply optimizations
export CCU_CONFIG_PATH="/Users/MAC/Documents/projects/caia/tools/cc-ultimate-config"
export CCU_MIN_CONFIDENCE=0.8        # Minimum confidence for auto-apply
export CCU_MAX_UPDATES=5             # Max auto-updates per session

# TURBO MODE SETTINGS
export MAX_PARALLEL=50         # 50 parallel processes (100 in turbo mode)
export PARALLEL_JOBS=50         # GNU parallel max jobs
export MAKEFLAGS="-j50"         # Parallel make builds
export NPM_CONFIG_JOBS=50       # npm parallel operations
export PYTEST_XDIST_WORKER_COUNT=50  # Parallel pytest
export RIPGREP_CONFIG_PATH=~/.claude/ripgrep_config  # 50 thread ripgrep

# RAM DISK (2GB for ultra-fast temp files)
export TMPDIR="/tmp/ramdisk"
export TEMP="/tmp/ramdisk"
export TMP="/tmp/ramdisk"

# GITHUB CLI (24hr cache, no pager)
gh config cache_ttl: 86400
gh config pager: cat

# TURBO MODE ACTIVATION
turbo_on()  # Activates 100 parallel processes + CCO
turbo_off() # Returns to 50 parallel processes
cco_on()    # Force enable CC Orchestrator
cco_off()   # Disable CC Orchestrator
```

### üöÄ Ultra-Speed Commands
```bash
# CC ORCHESTRATOR COMMANDS (PRIORITY)
cco_run task1 task2 task3    # Run tasks via CC Orchestrator
cco_parallel file1 file2     # Parallel file operations via CCO
cco_workflow project_name    # Execute full project workflow
cco_status                   # Show CCO instance status
cco_kill                     # Emergency stop all instances

# CCU COMMANDS (AUTO-OPTIMIZATION)
ccu_optimize                 # Apply all 82 optimizations
ccu_update                   # Research and apply new configs
ccu_rollback                 # Quick rollback to previous config
ccu_status                   # Show optimization status
ccu_daily                    # Run daily automation

# One-letter aliases
g = git
c = clear
l = ls -la
q = exit

# Quick functions
qc "message"  # Quick commit: add all, commit, push
update_all    # Update all repos in parallel (via CCO)
test_all      # Run all tests in parallel (via CCO)
build_all     # Build all projects in parallel (via CCO)

# Parallel execution (CCO-powered)
pp batch read file1 file2 file3  # Parallel file ops via CCO
pp git repo1 repo2 repo3         # Parallel git ops via CCO
pp test test_*.py                # Parallel tests via CCO
```

### Quick Commands
```bash
# CC ORCHESTRATOR INTEGRATION (DEFAULT)
# Update all repos in parallel via CCO
cco_run update_repos repo1 repo2 repo3

# Run all tests in parallel via CCO
cco_run test_parallel test_*.py

# Batch file operations via CCO
cco_parallel read file1 file2 file3

# CCU AUTO-OPTIMIZATION (RUNS FIRST)
# Auto-apply CC optimizations before any major task
ccu_optimize && cco_run your_task

# LEGACY (only if CCO unavailable)
source ~/.claude/batch_templates.sh && update_all_repos
~/.claude/parallel_executor.sh test test_*.py
~/.claude/parallel_executor.sh batch read file1 file2 file3
```

## Personal Reminders
- Take breaks every 2 hours
- Review PRs within 24 hours
- Update dependencies weekly
- Backup important work daily
- Learn one new thing daily
- Share knowledge with team

## Web Action Verification Rules
CRITICAL: Always verify web actions by checking actual URLs. This is MANDATORY.

### Automatic Verification Requirements
- **GitHub Repositories**: After creation/push, ALWAYS verify at the GitHub URL
- **GitHub Wikis**: After wiki updates, ALWAYS check https://github.com/{user}/{repo}/wiki
- **GitHub Pages**: After docs deployment, ALWAYS verify https://{user}.github.io/{repo}/
- **PyPI Packages**: After publishing, ALWAYS check https://pypi.org/project/{package}/
- **Documentation Sites**: After deployment, ALWAYS visit and verify the live URL
- **API Endpoints**: After creation, ALWAYS test with curl or WebFetch
- **Web Resources**: After any web action, ALWAYS verify accessibility

### Verification Formats to Remember
```bash
# GitHub Repository
https://github.com/prakashgbid/{repo-name}

# GitHub Wiki
https://github.com/prakashgbid/{repo-name}/wiki

# GitHub Pages
https://prakashgbid.github.io/{repo-name}/

# PyPI Package
https://pypi.org/project/{package-name}/

# npm Package
https://www.npmjs.com/package/{package-name}

# Docker Hub
https://hub.docker.com/r/{username}/{image-name}
```

### Automated Verification Commands
```bash
# Check GitHub repo exists
curl -s -o /dev/null -w "%{http_code}" https://github.com/prakashgbid/{repo}

# Check GitHub Pages is live
curl -s -o /dev/null -w "%{http_code}" https://prakashgbid.github.io/{repo}/

# Check PyPI package
pip search {package} || curl -s https://pypi.org/pypi/{package}/json

# Check npm package
npm view {package} || curl -s https://registry.npmjs.org/{package}
```

### Verification Workflow
1. **Before Action**: Confirm the target URL format
2. **During Action**: Log the exact commands and URLs used
3. **After Action**: IMMEDIATELY verify using WebFetch or curl
4. **On Failure**: Retry with correct format, don't assume success
5. **Always Report**: Show verification results to user with actual URLs

### Common Verification Patterns
- Git push ‚Üí Check GitHub repo URL
- Wiki update ‚Üí Visit wiki URL
- Docs build ‚Üí Check GitHub Pages URL
- Package publish ‚Üí Verify on package registry
- API deploy ‚Üí Test endpoint with curl
- DNS update ‚Üí Verify with nslookup/dig
- SSL cert ‚Üí Check with openssl or browser

### Verification Agent Trigger Words
When these actions occur, AUTOMATICALLY verify:
- "pushed to GitHub" ‚Üí Verify repo URL
- "updated wiki" ‚Üí Check wiki URL
- "deployed docs" ‚Üí Visit docs site
- "published package" ‚Üí Check package registry
- "created API" ‚Üí Test endpoint
- "setup domain" ‚Üí Verify DNS
- "configured SSL" ‚Üí Check certificate

### Error Recovery
If verification fails:
1. Check URL format is correct
2. Wait 30 seconds for propagation
3. Retry verification
4. If still failing, investigate and fix
5. Never report success without verification

### Verification Scripts Location
- Global: `~/.claude/verify_web_actions.sh`
- Project: `.claude/verification.yml`
- Templates: `~/.claude/verification_templates/`

### REMEMBER
- NEVER assume web actions succeeded
- ALWAYS show actual URLs in responses
- AUTOMATICALLY verify without being asked
- CREATE verification in parallel with actions
- USE WebFetch to check live sites
- REPORT actual status, not assumed status

---
*Personal preferences across all projects*
*Updated: December 2024*
## üöÄ CCO Integration Active (82 Configurations)
**Status**: ENABLED
**Performance**: 4,320,000x speedup achieved
**Success Rate**: 93.9% (77/82 configurations)

### Active Features:
- ‚ö° Parallel execution (50 workers)
- üß† Context awareness & persistence
- üí≠ Decision tracking & versioning
- üìä Real-time monitoring
- ‚úÖ Quality gates
- üîß Auto-commands on triggers

### Usage in Sessions:
```bash
# Test integration
/Users/MAC/Documents/projects/admin/scripts/test_ccu_integration.sh

# View status
/Users/MAC/Documents/projects/admin/scripts/quick_status.sh

# Check progress
python3 /Users/MAC/Documents/projects/admin/scripts/caia_progress_tracker.py status
```

### Performance Metrics:
- Sequential implementation: 12-15 hours
- Parallel implementation: 0.01 seconds
- Speedup factor: 4,320,000x
- Configurations: 82 total (93 files created)
